{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "import h5netcdf\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_in.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inBering.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inBering30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inBering30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inBering30day23.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inBering30day26.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inSH.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inSH30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inSH30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inSHWeddell30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inSHWeddell30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_inWeddell.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_in_30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_in_30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_in_30day23.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_in_30day26.csv']\n",
      "['C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_out.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outBering.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outBering30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outBering30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outBering30day23.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outBering30day26.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outSH.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outSH30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outSH30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outSHWedell30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outSHWedell30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_outWeddell.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_out_30day10.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_out_30day20.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_out_30day23.csv', 'C:\\\\Users\\\\Geraint Webb\\\\Documents\\\\FsdEmulation\\\\Data\\\\ds_out_30day26.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Geraint Webb\\AppData\\Local\\Temp\\ipykernel_18980\\4284052655.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_list_in=glob.glob(file_path+'\\ds_in*')\n",
      "C:\\Users\\Geraint Webb\\AppData\\Local\\Temp\\ipykernel_18980\\4284052655.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_list_out=glob.glob(file_path+'\\ds_out*')\n"
     ]
    }
   ],
   "source": [
    "file_path=r'C:\\Users\\Geraint Webb\\Documents\\FsdEmulation\\Data'\n",
    "data_list_in=glob.glob(file_path+'\\ds_in*')\n",
    "data_list_out=glob.glob(file_path+'\\ds_out*')\n",
    "data_list_in.sort()\n",
    "data_list_out.sort()\n",
    "print(data_list_in)\n",
    "print(data_list_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_arrays_in[0]: (45693, 13)\n",
      "Shape of data_arrays_in[1]: (41227, 13)\n",
      "Shape of data_arrays_in[2]: (30775, 13)\n",
      "Shape of data_arrays_in[3]: (56466, 13)\n",
      "Shape of data_arrays_in[4]: (95697, 13)\n",
      "Shape of data_arrays_in[5]: (35113, 13)\n",
      "Shape of data_arrays_in[6]: (44050, 13)\n",
      "Shape of data_arrays_in[7]: (41869, 13)\n",
      "Shape of data_arrays_in[8]: (3, 13)\n",
      "Shape of data_arrays_in[9]: (16273, 13)\n",
      "Shape of data_arrays_in[10]: (371, 13)\n",
      "Shape of data_arrays_in[11]: (15356, 13)\n",
      "Shape of data_arrays_in[12]: (86622, 13)\n",
      "Shape of data_arrays_in[13]: (71015, 13)\n",
      "Shape of data_arrays_in[14]: (27149, 13)\n",
      "Shape of data_arrays_in[15]: (34371, 13)\n",
      "Shape of data_arrays_out[0]: (45693, 12)\n",
      "Shape of data_arrays_out[1]: (41227, 12)\n",
      "Shape of data_arrays_out[2]: (30775, 12)\n",
      "Shape of data_arrays_out[3]: (56466, 12)\n",
      "Shape of data_arrays_out[4]: (95697, 12)\n",
      "Shape of data_arrays_out[5]: (35113, 12)\n",
      "Shape of data_arrays_out[6]: (44050, 12)\n",
      "Shape of data_arrays_out[7]: (41869, 12)\n",
      "Shape of data_arrays_out[8]: (3, 12)\n",
      "Shape of data_arrays_out[9]: (16273, 12)\n",
      "Shape of data_arrays_out[10]: (371, 12)\n",
      "Shape of data_arrays_out[11]: (15356, 12)\n",
      "Shape of data_arrays_out[12]: (86622, 12)\n",
      "Shape of data_arrays_out[13]: (71015, 12)\n",
      "Shape of data_arrays_out[14]: (27149, 12)\n",
      "Shape of data_arrays_out[15]: (34371, 12)\n"
     ]
    }
   ],
   "source": [
    "data_arrays_in = [np.loadtxt(file, delimiter=',') for file in data_list_in]\n",
    "data_arrays_out = [np.loadtxt(file, delimiter=',') for file in data_list_out]\n",
    "\n",
    "# Print the shapes of the arrays to verify\n",
    "for i, array in enumerate(data_arrays_in):\n",
    "    print(f\"Shape of data_arrays_in[{i}]: {array.shape}\")\n",
    "\n",
    "for i, array in enumerate(data_arrays_out):\n",
    "    print(f\"Shape of data_arrays_out[{i}]: {array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped_data_arrays_in: (642050, 13)\n"
     ]
    }
   ],
   "source": [
    "# Reshape each array in data_arrays_in to the specified shape and concatenate them\n",
    "reshaped_data_arrays_in = np.concatenate([array.reshape(-1, 13) for array in data_arrays_in])\n",
    "\n",
    "# Print the shape of the reshaped array to verify\n",
    "print(f\"Shape of reshaped_data_arrays_in: {reshaped_data_arrays_in.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped_data_arrays_out: (642050, 12)\n"
     ]
    }
   ],
   "source": [
    "# Reshape each array in data_arrays_out to the specified shape and concatenate them\n",
    "reshaped_data_arrays_out = np.concatenate([array.reshape(-1, 12) for array in data_arrays_out])\n",
    "\n",
    "# Print the shape of the reshaped array to verify\n",
    "print(f\"Shape of reshaped_data_arrays_out: {reshaped_data_arrays_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned_data_arrays_in: (614242, 13)\n",
      "Shape of cleaned_data_arrays_out: (614242, 12)\n"
     ]
    }
   ],
   "source": [
    "# Clean data_arrays_in and data_arrays_out\n",
    "cleaned_data_arrays_in = []\n",
    "cleaned_data_arrays_out = []\n",
    "\n",
    "for i in range(reshaped_data_arrays_in.shape[0]):\n",
    "        if not np.sum(reshaped_data_arrays_out[i])==0:\n",
    "            cleaned_data_arrays_in.append(reshaped_data_arrays_in[i])\n",
    "            cleaned_data_arrays_out.append(reshaped_data_arrays_out[i])\n",
    "\n",
    "# Convert lists back to numpy arrays if needed\n",
    "cleaned_data_arrays_in = np.array(cleaned_data_arrays_in)\n",
    "cleaned_data_arrays_out = np.array(cleaned_data_arrays_out)\n",
    "\n",
    "# Print the shapes of the cleaned arrays to verify\n",
    "print(f\"Shape of cleaned_data_arrays_in: {cleaned_data_arrays_in.shape}\")\n",
    "print(f\"Shape of cleaned_data_arrays_out: {cleaned_data_arrays_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the orders of magnitude difference\n",
    "def calculate_orders_of_magnitude_difference(predictions, actuals):\n",
    "    differences = torch.abs(predictions - actuals)\n",
    "    orders_of_magnitude_diff = torch.log10(differences + 1e-10) - torch.log10(torch.abs(actuals) + 1e-10)\n",
    "    return torch.mean(torch.abs(orders_of_magnitude_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Check the version of PyTorch\n",
    "print(torch.cuda.is_available())  # Check if CUDA is available\n",
    "print(torch.cuda.current_device())  # Check the current CUDA device\n",
    "print(torch.cuda.get_device_name(0))  # Get the name of the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [100/4000], MSE Loss: 0.000199 Sum loss: 0.000007 Sign Loss: 0.000000\n",
      "Epoch [200/4000], MSE Loss: 0.000013 Sum loss: 0.000001 Sign Loss: 0.000000\n",
      "Epoch [300/4000], MSE Loss: 0.000012 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [400/4000], MSE Loss: 0.000012 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [500/4000], MSE Loss: 0.000011 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [600/4000], MSE Loss: 0.000011 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [700/4000], MSE Loss: 0.000011 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [800/4000], MSE Loss: 0.000011 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [900/4000], MSE Loss: 0.000010 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1000/4000], MSE Loss: 0.000010 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1100/4000], MSE Loss: 0.000010 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1200/4000], MSE Loss: 0.000010 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1300/4000], MSE Loss: 0.000010 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1400/4000], MSE Loss: 0.000009 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1500/4000], MSE Loss: 0.000009 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1600/4000], MSE Loss: 0.000009 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1700/4000], MSE Loss: 0.000008 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1800/4000], MSE Loss: 0.000008 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [1900/4000], MSE Loss: 0.000007 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2000/4000], MSE Loss: 0.000007 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2100/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2200/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2300/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2400/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2500/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2600/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2700/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2800/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [2900/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3000/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3100/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3200/4000], MSE Loss: 0.000009 Sum loss: 0.000001 Sign Loss: 0.000000\n",
      "Epoch [3300/4000], MSE Loss: 0.000008 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3400/4000], MSE Loss: 0.000007 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3500/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3600/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3700/4000], MSE Loss: 0.000006 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3800/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [3900/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Epoch [4000/4000], MSE Loss: 0.000005 Sum loss: 0.000000 Sign Loss: 0.000000\n",
      "Test Mean Squared Error: 0.00000518656543135876\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to GPU if available\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data_arrays_in, cleaned_data_arrays_out, test_size=0.2, random_state=42)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(X_train.shape[1], 256)\n",
    "        self.hidden2 = nn.Linear(256, 128)\n",
    "        self.hidden3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, y_train_tensor.shape[1])\n",
    "        #self.hidden1 = nn.Linear(X_train.shape[1], 100)\n",
    "        #self.hidden2 = nn.Linear(100, 100)\n",
    "        #self.output = nn.Linear(100, y_train_tensor.shape[1])\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = PhysicsInformedNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Custom loss function to enforce the sum of outputs to be zero\n",
    "def custom_loss(output, target):\n",
    "    mse_loss = criterion(output, target)\n",
    "\n",
    "    sign_penalty = 0\n",
    "    for i in range(output.shape[1]):\n",
    "        sign_penalty += torch.mean(torch.relu(-output[:, i] * torch.sign(target[:, i])))\n",
    "    sign_penalty = sign_penalty / output.shape[1]\n",
    "    \n",
    "    sign_loss = sign_penalty**2\n",
    "    sum_constraint = torch.sum(output, dim=1)\n",
    "    sum_loss = torch.mean(sum_constraint ** 2)\n",
    "    return [mse_loss, sum_loss, sign_loss]\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = custom_loss(outputs, y_train_tensor)\n",
    "    loss_sum = loss[0] + loss[1] + 1000 * loss[2]\n",
    "    loss_sum.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], MSE Loss: {loss[0].item():.6f} Sum loss: {loss[1].item():.6f} Sign Loss: {loss[2].item():.6f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    print(f'Test Mean Squared Error: {mse.item():.20f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in=cleaned_data_arrays_in\n",
    "ds_out=cleaned_data_arrays_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5209e-04,  1.8293e-04,  2.3211e-04,  2.0906e-04,  2.9681e-04,\n",
      "         1.8958e-04,  3.4300e-04,  5.5338e-04,  7.8551e-05, -4.4988e-04,\n",
      "        -2.2279e-04, -1.5576e-03], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor(7.2506e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[4.89162505e-01 1.25346109e-01 7.97971189e-02 6.17226288e-02\n",
      " 5.17611504e-02 4.56434675e-02 4.21169475e-02 4.08703759e-02\n",
      " 4.19333428e-02 2.16227453e-02 2.02643832e-07 2.34035160e-05\n",
      " 2.08282971e-02]\n",
      "[ 1.18911266e-05  3.28570604e-05  6.70701265e-05  1.19619071e-04\n",
      "  1.97485089e-04  3.08703631e-04  4.61630523e-04  6.63734972e-04\n",
      "  9.20038670e-04 -2.75943801e-03 -2.02643832e-07 -2.34035160e-05]\n"
     ]
    }
   ],
   "source": [
    "k=2500\n",
    "print(model(torch.tensor(ds_in[k], dtype=torch.float32).to(device)))\n",
    "print(sum(model(torch.tensor(ds_in[k], dtype=torch.float32).to(device))))\n",
    "print(ds_in[k])\n",
    "print(ds_out[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of incorrect different negative signs: 462846 As a %: 6.28\n"
     ]
    }
   ],
   "source": [
    "# Move ds_in and ds_out to tensors on the appropriate device\n",
    "ds_in_tensor = torch.tensor(ds_in, dtype=torch.float32).to(device)\n",
    "ds_out_tensor = torch.tensor(ds_out, dtype=torch.float32).to(device)\n",
    "\n",
    "# Get predictions for the entire dataset in one go\n",
    "predicted_outputs = model(ds_in_tensor).cpu()\n",
    "actual_outputs = ds_out_tensor.cpu()\n",
    "\n",
    "# Compare the signs of the predicted and actual outputs\n",
    "predicted_signs = torch.sign(predicted_outputs)\n",
    "actual_signs = torch.sign(actual_outputs)\n",
    "\n",
    "# Count the number of different signs\n",
    "negative_sign_differences = torch.sum(predicted_signs != actual_signs).item()\n",
    "\n",
    "print(f'Total number of incorrect different negative signs: {negative_sign_differences} As a %: {100 * negative_sign_differences / (ds_in.shape[0] * ds_out.shape[1]):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between predicted and actual outputs: 0.0007020539\n"
     ]
    }
   ],
   "source": [
    "# Move ds_in and ds_out to tensors on the appropriate device\n",
    "ds_in_tensor = torch.tensor(ds_in, dtype=torch.float32).to(device)\n",
    "ds_out_tensor = torch.tensor(ds_out, dtype=torch.float32).to(device)\n",
    "\n",
    "# Get predictions for the entire dataset in one go\n",
    "predicted_outputs = model(ds_in_tensor).cpu()\n",
    "actual_outputs = ds_out_tensor.cpu()\n",
    "\n",
    "#Calulate the average % difference between the predicted and actual outputs\n",
    "percent_diff = torch.mean(torch.abs((predicted_outputs-actual_outputs))).item()\n",
    "\n",
    "print(f'Average difference between predicted and actual outputs: {percent_diff:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Orders of Magnitude Difference: 1.214884\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    avg_orders_of_magnitude_diff = calculate_orders_of_magnitude_difference(test_predictions, y_test_tensor)\n",
    "    print(f'Average Orders of Magnitude Difference: {avg_orders_of_magnitude_diff.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [100/4000], MSE Loss: 0.018804 Sum loss: 0.011167 Sign Loss: 0.000000\n",
      "Epoch [200/4000], MSE Loss: 0.022369 Sum loss: 0.002595 Sign Loss: 0.000000\n",
      "Epoch [300/4000], MSE Loss: 0.021428 Sum loss: 0.002465 Sign Loss: 0.000000\n",
      "Epoch [400/4000], MSE Loss: 0.020403 Sum loss: 0.002231 Sign Loss: 0.000000\n",
      "Epoch [500/4000], MSE Loss: 0.019231 Sum loss: 0.002095 Sign Loss: 0.000000\n",
      "Epoch [600/4000], MSE Loss: 0.018040 Sum loss: 0.001963 Sign Loss: 0.000000\n",
      "Epoch [700/4000], MSE Loss: 0.016866 Sum loss: 0.001840 Sign Loss: 0.000000\n",
      "Epoch [800/4000], MSE Loss: 0.015718 Sum loss: 0.001719 Sign Loss: 0.000000\n",
      "Epoch [900/4000], MSE Loss: 0.014617 Sum loss: 0.001616 Sign Loss: 0.000000\n",
      "Epoch [1000/4000], MSE Loss: 0.013575 Sum loss: 0.001513 Sign Loss: 0.000000\n",
      "Epoch [1100/4000], MSE Loss: 0.013018 Sum loss: 0.001473 Sign Loss: 0.000000\n",
      "Epoch [1200/4000], MSE Loss: 0.012466 Sum loss: 0.001428 Sign Loss: 0.000000\n",
      "Epoch [1300/4000], MSE Loss: 0.011954 Sum loss: 0.001364 Sign Loss: 0.000000\n",
      "Epoch [1400/4000], MSE Loss: 0.011467 Sum loss: 0.001303 Sign Loss: 0.000000\n",
      "Epoch [1500/4000], MSE Loss: 0.011469 Sum loss: 0.001304 Sign Loss: 0.000000\n",
      "Epoch [1600/4000], MSE Loss: 0.011460 Sum loss: 0.001293 Sign Loss: 0.000000\n",
      "Epoch [1700/4000], MSE Loss: 0.011461 Sum loss: 0.001270 Sign Loss: 0.000000\n",
      "Epoch [1800/4000], MSE Loss: 0.011462 Sum loss: 0.001246 Sign Loss: 0.000000\n",
      "Epoch [1900/4000], MSE Loss: 0.011464 Sum loss: 0.001224 Sign Loss: 0.000000\n",
      "Epoch [2000/4000], MSE Loss: 0.011466 Sum loss: 0.001201 Sign Loss: 0.000000\n",
      "Epoch [2100/4000], MSE Loss: 0.011468 Sum loss: 0.001179 Sign Loss: 0.000000\n",
      "Epoch [2200/4000], MSE Loss: 0.011471 Sum loss: 0.001158 Sign Loss: 0.000000\n",
      "Epoch [2300/4000], MSE Loss: 0.011474 Sum loss: 0.001138 Sign Loss: 0.000000\n",
      "Epoch [2400/4000], MSE Loss: 0.011478 Sum loss: 0.001118 Sign Loss: 0.000000\n",
      "Epoch [2500/4000], MSE Loss: 0.011481 Sum loss: 0.001100 Sign Loss: 0.000000\n",
      "Epoch [2600/4000], MSE Loss: 0.011485 Sum loss: 0.001082 Sign Loss: 0.000000\n",
      "Epoch [2700/4000], MSE Loss: 0.011487 Sum loss: 0.001065 Sign Loss: 0.000000\n",
      "Epoch [2800/4000], MSE Loss: 0.011490 Sum loss: 0.001049 Sign Loss: 0.000000\n",
      "Epoch [2900/4000], MSE Loss: 0.011492 Sum loss: 0.001033 Sign Loss: 0.000000\n",
      "Epoch [3000/4000], MSE Loss: 0.011494 Sum loss: 0.001018 Sign Loss: 0.000000\n",
      "Epoch [3100/4000], MSE Loss: 0.011495 Sum loss: 0.001004 Sign Loss: 0.000000\n",
      "Epoch [3200/4000], MSE Loss: 0.011497 Sum loss: 0.000991 Sign Loss: 0.000000\n",
      "Epoch [3300/4000], MSE Loss: 0.011498 Sum loss: 0.000978 Sign Loss: 0.000000\n",
      "Epoch [3400/4000], MSE Loss: 0.011498 Sum loss: 0.000965 Sign Loss: 0.000000\n",
      "Epoch [3500/4000], MSE Loss: 0.011497 Sum loss: 0.000953 Sign Loss: 0.000000\n",
      "Epoch [3600/4000], MSE Loss: 0.011497 Sum loss: 0.000942 Sign Loss: 0.000000\n",
      "Epoch [3700/4000], MSE Loss: 0.011496 Sum loss: 0.000931 Sign Loss: 0.000000\n",
      "Epoch [3800/4000], MSE Loss: 0.011494 Sum loss: 0.000921 Sign Loss: 0.000000\n",
      "Epoch [3900/4000], MSE Loss: 0.011491 Sum loss: 0.000911 Sign Loss: 0.000000\n",
      "Epoch [4000/4000], MSE Loss: 0.011489 Sum loss: 0.000902 Sign Loss: 0.000000\n",
      "Test Mean Squared Error: 0.01148907374590635300\n"
     ]
    }
   ],
   "source": [
    "#High sign test\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to GPU if available\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data_arrays_in, cleaned_data_arrays_out, test_size=0.2, random_state=42)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(X_train.shape[1], 256)\n",
    "        self.hidden2 = nn.Linear(256, 128)\n",
    "        self.hidden3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, y_train_tensor.shape[1])\n",
    "        #self.hidden1 = nn.Linear(X_train.shape[1], 100)\n",
    "        #self.hidden2 = nn.Linear(100, 100)\n",
    "        #self.output = nn.Linear(100, y_train_tensor.shape[1])\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = PhysicsInformedNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Custom loss function to enforce the sum of outputs to be zero\n",
    "def custom_loss(output, target):\n",
    "    mse_loss = criterion(output, target)\n",
    "\n",
    "    sign_penalty = 0\n",
    "    for i in range(output.shape[1]):\n",
    "        sign_penalty += torch.mean(torch.relu(-output[:, i] * torch.sign(target[:, i])))\n",
    "    sign_penalty = sign_penalty / output.shape[1]\n",
    "    \n",
    "    sign_loss = sign_penalty**2\n",
    "    sum_constraint = torch.sum(output, dim=1)\n",
    "    sum_loss = torch.mean(sum_constraint ** 2)\n",
    "    return [mse_loss, sum_loss, sign_loss]\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = custom_loss(outputs, y_train_tensor)\n",
    "    loss_sum = loss[0] + loss[1] + 1000000000000000 * loss[2]\n",
    "    loss_sum.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], MSE Loss: {loss[0].item():.6f} Sum loss: {loss[1].item():.6f} Sign Loss: {loss[2].item():.6f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    print(f'Test Mean Squared Error: {mse.item():.20f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.2230e-02,  7.3560e-02,  1.4425e-02,  3.3060e-02,  1.3424e-02,\n",
      "         1.5285e-01,  3.9333e-03,  1.2096e-03,  1.3103e-04, -3.0655e-04,\n",
      "        -3.8174e-04, -3.2172e-01], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[4.89162505e-01 1.25346109e-01 7.97971189e-02 6.17226288e-02\n",
      " 5.17611504e-02 4.56434675e-02 4.21169475e-02 4.08703759e-02\n",
      " 4.19333428e-02 2.16227453e-02 2.02643832e-07 2.34035160e-05\n",
      " 2.08282971e-02]\n",
      "[ 1.18911266e-05  3.28570604e-05  6.70701265e-05  1.19619071e-04\n",
      "  1.97485089e-04  3.08703631e-04  4.61630523e-04  6.63734972e-04\n",
      "  9.20038670e-04 -2.75943801e-03 -2.02643832e-07 -2.34035160e-05]\n"
     ]
    }
   ],
   "source": [
    "k=2500\n",
    "print(model(torch.tensor(ds_in[k], dtype=torch.float32).to(device)))\n",
    "print(sum(model(torch.tensor(ds_in[k], dtype=torch.float32).to(device))))\n",
    "print(ds_in[k])\n",
    "print(ds_out[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of incorrect different negative signs: 152141 As a %: 2.06\n"
     ]
    }
   ],
   "source": [
    "# Move ds_in and ds_out to tensors on the appropriate device\n",
    "ds_in_tensor = torch.tensor(ds_in, dtype=torch.float32).to(device)\n",
    "ds_out_tensor = torch.tensor(ds_out, dtype=torch.float32).to(device)\n",
    "\n",
    "# Get predictions for the entire dataset in one go\n",
    "predicted_outputs = model(ds_in_tensor).cpu()\n",
    "actual_outputs = ds_out_tensor.cpu()\n",
    "\n",
    "# Compare the signs of the predicted and actual outputs\n",
    "predicted_signs = torch.sign(predicted_outputs)\n",
    "actual_signs = torch.sign(actual_outputs)\n",
    "\n",
    "# Count the number of different signs\n",
    "negative_sign_differences = torch.sum(predicted_signs != actual_signs).item()\n",
    "\n",
    "print(f'Total number of incorrect different negative signs: {negative_sign_differences} As a %: {100 * negative_sign_differences / (ds_in.shape[0] * ds_out.shape[1]):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Orders of Magnitude Difference: 2.495350\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    avg_orders_of_magnitude_diff = calculate_orders_of_magnitude_difference(test_predictions, y_test_tensor)\n",
    "    print(f'Average Orders of Magnitude Difference: {avg_orders_of_magnitude_diff.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
